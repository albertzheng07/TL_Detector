{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trafic Light Classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azheng/anaconda3/envs/carnd-term1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/azheng/anaconda3/envs/carnd-term1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/Users/azheng/anaconda3/envs/carnd-term1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/azheng/anaconda3/envs/carnd-term1/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124d22a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "x_label = []\n",
    "for img_class, directory in enumerate(['red', 'yellow', 'green', 'none']):\n",
    "    for i, file_name in enumerate(glob.glob(\"{}/*.jpg\".format(directory))):\n",
    "        file = cv2.imread(file_name)\n",
    "\n",
    "        file = cv2.cvtColor(file, cv2.COLOR_BGR2RGB);\n",
    "        resized = cv2.resize(file, (32,32))\n",
    "\n",
    "        X_train.append(resized/255.)\n",
    "        x_label.append(img_class)\n",
    "        \n",
    "        #if (i < 3):\n",
    "        #    plt.imshow(rgb)\n",
    "        #    plt.show()\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "x_label = np.array(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import losses, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_labels = to_categorical(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 4\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(64, 32, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# Dropout(0.8)\n",
    "# model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# Dropout(0.8)\n",
    "# model.add(Flatten())\n",
    "\n",
    "# #model.add(Dense(128, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Dense(8, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.categorical_crossentropy\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 330 samples, validate on 37 samples\n",
      "Epoch 1/30\n",
      "330/330 [==============================] - 0s - loss: 1.2380 - acc: 0.4000 - val_loss: 2.1980 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "330/330 [==============================] - 0s - loss: 0.9078 - acc: 0.7182 - val_loss: 2.1328 - val_acc: 0.0270\n",
      "Epoch 3/30\n",
      "330/330 [==============================] - 0s - loss: 0.6113 - acc: 0.8576 - val_loss: 2.3838 - val_acc: 0.0270\n",
      "Epoch 4/30\n",
      "330/330 [==============================] - 0s - loss: 0.4250 - acc: 0.8788 - val_loss: 2.4102 - val_acc: 0.0270\n",
      "Epoch 5/30\n",
      "330/330 [==============================] - 0s - loss: 0.3081 - acc: 0.9242 - val_loss: 1.8928 - val_acc: 0.4865\n",
      "Epoch 6/30\n",
      "330/330 [==============================] - 0s - loss: 0.2369 - acc: 0.9515 - val_loss: 1.7999 - val_acc: 0.5946\n",
      "Epoch 7/30\n",
      "330/330 [==============================] - 0s - loss: 0.1934 - acc: 0.9455 - val_loss: 1.4833 - val_acc: 0.6757\n",
      "Epoch 8/30\n",
      "330/330 [==============================] - 0s - loss: 0.1463 - acc: 0.9636 - val_loss: 1.5859 - val_acc: 0.6757\n",
      "Epoch 9/30\n",
      "330/330 [==============================] - 0s - loss: 0.1199 - acc: 0.9727 - val_loss: 1.9964 - val_acc: 0.6216\n",
      "Epoch 10/30\n",
      "330/330 [==============================] - 0s - loss: 0.1012 - acc: 0.9848 - val_loss: 1.7015 - val_acc: 0.6486\n",
      "Epoch 11/30\n",
      "330/330 [==============================] - 0s - loss: 0.0853 - acc: 0.9879 - val_loss: 1.7842 - val_acc: 0.6757\n",
      "Epoch 12/30\n",
      "330/330 [==============================] - 0s - loss: 0.0913 - acc: 0.9879 - val_loss: 1.7053 - val_acc: 0.6486\n",
      "Epoch 13/30\n",
      "330/330 [==============================] - 0s - loss: 0.0837 - acc: 0.9788 - val_loss: 1.8366 - val_acc: 0.6486\n",
      "Epoch 14/30\n",
      "330/330 [==============================] - 0s - loss: 0.0607 - acc: 0.9970 - val_loss: 1.6650 - val_acc: 0.6757\n",
      "Epoch 15/30\n",
      "330/330 [==============================] - 0s - loss: 0.0575 - acc: 0.9970 - val_loss: 1.8780 - val_acc: 0.6486\n",
      "Epoch 16/30\n",
      "330/330 [==============================] - 0s - loss: 0.0507 - acc: 0.9970 - val_loss: 1.5077 - val_acc: 0.6757\n",
      "Epoch 17/30\n",
      "330/330 [==============================] - 0s - loss: 0.0455 - acc: 1.0000 - val_loss: 1.7579 - val_acc: 0.6757\n",
      "Epoch 18/30\n",
      "330/330 [==============================] - 0s - loss: 0.0390 - acc: 1.0000 - val_loss: 1.7861 - val_acc: 0.6757\n",
      "Epoch 19/30\n",
      "330/330 [==============================] - 0s - loss: 0.0374 - acc: 1.0000 - val_loss: 1.8060 - val_acc: 0.6757\n",
      "Epoch 20/30\n",
      "330/330 [==============================] - 0s - loss: 0.0306 - acc: 1.0000 - val_loss: 1.9149 - val_acc: 0.6757\n",
      "Epoch 21/30\n",
      "330/330 [==============================] - 0s - loss: 0.0288 - acc: 1.0000 - val_loss: 1.7993 - val_acc: 0.6757\n",
      "Epoch 22/30\n",
      "330/330 [==============================] - 0s - loss: 0.0257 - acc: 1.0000 - val_loss: 1.9609 - val_acc: 0.6757\n",
      "Epoch 23/30\n",
      "330/330 [==============================] - 0s - loss: 0.0231 - acc: 1.0000 - val_loss: 1.8820 - val_acc: 0.6757\n",
      "Epoch 24/30\n",
      "330/330 [==============================] - 0s - loss: 0.0211 - acc: 1.0000 - val_loss: 2.0315 - val_acc: 0.6757\n",
      "Epoch 25/30\n",
      "330/330 [==============================] - 0s - loss: 0.0198 - acc: 1.0000 - val_loss: 2.0183 - val_acc: 0.6757\n",
      "Epoch 26/30\n",
      "330/330 [==============================] - 0s - loss: 0.0197 - acc: 1.0000 - val_loss: 1.9754 - val_acc: 0.6757\n",
      "Epoch 27/30\n",
      "330/330 [==============================] - 0s - loss: 0.0187 - acc: 1.0000 - val_loss: 2.0910 - val_acc: 0.6757\n",
      "Epoch 28/30\n",
      "330/330 [==============================] - 0s - loss: 0.0168 - acc: 1.0000 - val_loss: 1.8854 - val_acc: 0.6757\n",
      "Epoch 29/30\n",
      "330/330 [==============================] - 0s - loss: 0.0152 - acc: 1.0000 - val_loss: 2.1170 - val_acc: 0.6757\n",
      "Epoch 30/30\n",
      "330/330 [==============================] - 0s - loss: 0.0143 - acc: 1.0000 - val_loss: 2.1324 - val_acc: 0.6757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd29e0d9b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, categorical_labels, batch_size=32, epochs=30, verbose=True, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, categorical_labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22704448965086274, 0.9673024529657182]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/367 [===========================>..] - ETA: 0s0 [9.9975044e-01 1.5356040e-04 3.5160800e-05 6.0838513e-05] [1. 0. 0. 0.]\n",
      "1 [9.9237567e-01 2.5044484e-03 1.7422166e-04 4.9455818e-03] [1. 0. 0. 0.]\n",
      "2 [9.9824762e-01 6.2372774e-04 3.4034703e-04 7.8831310e-04] [1. 0. 0. 0.]\n",
      "3 [9.9970955e-01 3.7521364e-05 4.1012070e-05 2.1187234e-04] [1. 0. 0. 0.]\n",
      "4 [9.9705005e-01 7.1893993e-04 3.7807600e-05 2.1931482e-03] [1. 0. 0. 0.]\n",
      "5 [9.9918705e-01 5.7857466e-04 5.8399532e-06 2.2857181e-04] [1. 0. 0. 0.]\n",
      "6 [0.79770935 0.00652057 0.02444451 0.17132555] [1. 0. 0. 0.]\n",
      "7 [0.91886985 0.01701685 0.01803443 0.0460789 ] [1. 0. 0. 0.]\n",
      "8 [0.87408185 0.02334581 0.01553405 0.08703832] [1. 0. 0. 0.]\n",
      "9 [0.8102479  0.00812984 0.00362214 0.1780002 ] [1. 0. 0. 0.]\n",
      "10 [9.8176438e-01 1.1574444e-02 6.6461149e-03 1.5057824e-05] [1. 0. 0. 0.]\n",
      "11 [9.8970616e-01 9.8179342e-05 9.9877203e-03 2.0798109e-04] [1. 0. 0. 0.]\n",
      "12 [0.9647956  0.01799259 0.01547147 0.0017403 ] [1. 0. 0. 0.]\n",
      "13 [9.9190301e-01 2.7025440e-03 5.3230533e-03 7.1287141e-05] [1. 0. 0. 0.]\n",
      "14 [9.99962330e-01 1.29617465e-05 6.50805396e-06 1.81189898e-05] [1. 0. 0. 0.]\n",
      "15 [9.9858093e-01 1.3695811e-03 1.6746149e-05 3.2726202e-05] [1. 0. 0. 0.]\n",
      "16 [9.9876249e-01 1.2307215e-03 4.2485608e-06 2.5213117e-06] [1. 0. 0. 0.]\n",
      "17 [9.4575632e-01 3.8890030e-02 1.5337428e-02 1.6209789e-05] [1. 0. 0. 0.]\n",
      "18 [9.99535561e-01 3.41409555e-04 1.57530194e-05 1.07307744e-04] [1. 0. 0. 0.]\n",
      "19 [9.9893850e-01 9.4139396e-04 4.7306676e-05 7.2862102e-05] [1. 0. 0. 0.]\n",
      "20 [9.9982721e-01 6.0672282e-06 1.3235752e-05 1.5350468e-04] [1. 0. 0. 0.]\n",
      "21 [9.9803156e-01 1.1000948e-03 6.7600937e-05 8.0074783e-04] [1. 0. 0. 0.]\n",
      "22 [9.9954659e-01 3.1459982e-05 2.4648169e-05 3.9730466e-04] [1. 0. 0. 0.]\n",
      "23 [9.9990714e-01 3.2893029e-05 1.6911741e-05 4.3001608e-05] [1. 0. 0. 0.]\n",
      "24 [9.9990714e-01 3.2893029e-05 1.6911741e-05 4.3001608e-05] [1. 0. 0. 0.]\n",
      "25 [9.7860020e-01 4.6657091e-03 1.1596409e-04 1.6618060e-02] [1. 0. 0. 0.]\n",
      "26 [9.9935168e-01 6.1194709e-04 7.1321974e-06 2.9249846e-05] [1. 0. 0. 0.]\n",
      "27 [9.9974269e-01 3.5723628e-05 6.5685381e-05 1.5597175e-04] [1. 0. 0. 0.]\n",
      "28 [9.9746346e-01 2.2129545e-03 2.7699309e-04 4.6660236e-05] [1. 0. 0. 0.]\n",
      "29 [9.9995589e-01 2.7547699e-06 2.2915763e-05 1.8521152e-05] [1. 0. 0. 0.]\n",
      "30 [9.7768003e-01 8.6429464e-03 1.3488227e-02 1.8879811e-04] [1. 0. 0. 0.]\n",
      "31 [9.9981910e-01 1.6467509e-04 1.0858186e-05 5.4542388e-06] [1. 0. 0. 0.]\n",
      "32 [9.9969244e-01 4.2646498e-05 2.4356224e-05 2.4065912e-04] [1. 0. 0. 0.]\n",
      "33 [9.9718165e-01 1.8415781e-03 9.4496243e-04 3.1892723e-05] [1. 0. 0. 0.]\n",
      "34 [9.9993253e-01 6.5719229e-05 6.9525561e-07 1.0626079e-06] [1. 0. 0. 0.]\n",
      "35 [9.9985540e-01 1.2041066e-04 2.5571794e-06 2.1607349e-05] [1. 0. 0. 0.]\n",
      "36 [9.9978822e-01 6.9928342e-06 1.6245737e-06 2.0311143e-04] [1. 0. 0. 0.]\n",
      "37 [9.9992204e-01 6.9591435e-05 1.5499253e-06 6.8537843e-06] [1. 0. 0. 0.]\n",
      "38 [9.9995995e-01 5.6057552e-06 3.7176299e-06 3.0797684e-05] [1. 0. 0. 0.]\n",
      "39 [9.7758752e-01 8.4401350e-03 1.3785877e-02 1.8641868e-04] [1. 0. 0. 0.]\n",
      "40 [9.9990928e-01 3.3716646e-05 1.6009169e-05 4.0984760e-05] [1. 0. 0. 0.]\n",
      "41 [9.9750060e-01 6.1311388e-05 5.4699788e-04 1.8911524e-03] [1. 0. 0. 0.]\n",
      "42 [9.9827993e-01 1.1984763e-03 1.1895868e-05 5.0967920e-04] [1. 0. 0. 0.]\n",
      "43 [9.9573475e-01 3.9181048e-03 3.2450588e-04 2.2702226e-05] [1. 0. 0. 0.]\n",
      "44 [9.9957269e-01 9.2816648e-05 2.9325074e-06 3.3152773e-04] [1. 0. 0. 0.]\n",
      "45 [9.7341406e-01 2.1153145e-02 4.5814467e-04 4.9746553e-03] [1. 0. 0. 0.]\n",
      "46 [9.9855930e-01 1.8681907e-04 5.2279612e-04 7.3106785e-04] [1. 0. 0. 0.]\n",
      "47 [9.9990714e-01 3.2893029e-05 1.6911741e-05 4.3001608e-05] [1. 0. 0. 0.]\n",
      "48 [0.9883471  0.00113857 0.00452596 0.00598843] [1. 0. 0. 0.]\n",
      "49 [9.9967813e-01 3.1119495e-04 4.3215068e-06 6.4248939e-06] [1. 0. 0. 0.]\n",
      "50 [9.9995220e-01 1.2355226e-06 4.0808800e-06 4.2500313e-05] [1. 0. 0. 0.]\n",
      "51 [9.9939585e-01 3.1515129e-04 9.8381046e-05 1.9057446e-04] [1. 0. 0. 0.]\n",
      "52 [9.9938512e-01 5.6101842e-04 2.3024137e-05 3.0874584e-05] [1. 0. 0. 0.]\n",
      "53 [9.7806019e-01 8.2168784e-03 1.3539606e-02 1.8331247e-04] [1. 0. 0. 0.]\n",
      "54 [9.9794835e-01 2.0447737e-03 2.0554376e-06 4.9284258e-06] [1. 0. 0. 0.]\n",
      "55 [9.9864465e-01 4.9420603e-04 4.8928411e-04 3.7190694e-04] [1. 0. 0. 0.]\n",
      "56 [9.9942857e-01 5.1293592e-04 3.1199049e-06 5.5345696e-05] [1. 0. 0. 0.]\n",
      "57 [9.8295391e-01 2.5604849e-04 2.7092872e-04 1.6519165e-02] [1. 0. 0. 0.]\n",
      "58 [9.99864578e-01 1.13198286e-04 5.77254787e-06 1.65156853e-05] [1. 0. 0. 0.]\n",
      "59 [9.910026e-01 7.987740e-05 5.777259e-05 8.859743e-03] [1. 0. 0. 0.]\n",
      "60 [0.9436066  0.00363224 0.00609411 0.04666702] [1. 0. 0. 0.]\n",
      "61 [9.9935335e-01 3.8683962e-04 1.5795312e-04 1.0182787e-04] [1. 0. 0. 0.]\n",
      "62 [9.9997067e-01 2.5434933e-06 6.1066053e-06 2.0731779e-05] [1. 0. 0. 0.]\n",
      "63 [9.763421e-01 2.308640e-03 2.134201e-02 7.307266e-06] [1. 0. 0. 0.]\n",
      "64 [9.9961567e-01 7.1391281e-07 3.9692019e-05 3.4392098e-04] [1. 0. 0. 0.]\n",
      "65 [9.9990726e-01 3.2697775e-05 1.6912438e-05 4.3167405e-05] [1. 0. 0. 0.]\n",
      "66 [9.2438048e-01 6.8178542e-02 2.9941185e-04 7.1415189e-03] [1. 0. 0. 0.]\n",
      "67 [9.9673706e-01 3.7672555e-05 7.2128267e-04 2.5040335e-03] [1. 0. 0. 0.]\n",
      "68 [9.9291259e-01 3.7407482e-03 1.3294141e-04 3.2137495e-03] [1. 0. 0. 0.]\n",
      "69 [9.9989557e-01 1.0058347e-04 2.9431206e-07 3.5874452e-06] [1. 0. 0. 0.]\n",
      "70 [9.7777426e-01 8.3962232e-03 1.3644359e-02 1.8516798e-04] [1. 0. 0. 0.]\n",
      "71 [9.9990714e-01 3.2893029e-05 1.6911741e-05 4.3001608e-05] [1. 0. 0. 0.]\n",
      "72 [9.9792778e-01 1.9416066e-03 8.8165416e-06 1.2179871e-04] [1. 0. 0. 0.]\n",
      "73 [9.9989569e-01 3.6159945e-05 1.9803323e-05 4.8293263e-05] [1. 0. 0. 0.]\n",
      "74 [9.9837518e-01 2.4293148e-04 1.4391806e-05 1.3674628e-03] [1. 0. 0. 0.]\n",
      "75 [0.94840145 0.00479721 0.00400172 0.04279967] [1. 0. 0. 0.]\n",
      "76 [9.9804175e-01 1.8238772e-03 3.8242448e-05 9.6121883e-05] [1. 0. 0. 0.]\n",
      "77 [9.9990714e-01 3.2893029e-05 1.6911741e-05 4.3001608e-05] [1. 0. 0. 0.]\n",
      "78 [9.9999869e-01 1.2036342e-07 4.6551126e-08 1.1476997e-06] [1. 0. 0. 0.]\n",
      "79 [9.9997902e-01 6.6986672e-08 3.4110608e-09 2.0967153e-05] [1. 0. 0. 0.]\n",
      "80 [9.9978930e-01 2.0835271e-04 5.2843342e-07 1.9155798e-06] [1. 0. 0. 0.]\n",
      "81 [9.9973994e-01 1.9007205e-04 3.9939987e-05 3.0046845e-05] [1. 0. 0. 0.]\n",
      "82 [9.8329461e-01 7.5815001e-04 2.2445543e-04 1.5722746e-02] [1. 0. 0. 0.]\n",
      "83 [9.9999475e-01 1.2260359e-06 1.3539671e-06 2.7142751e-06] [1. 0. 0. 0.]\n",
      "84 [9.9696153e-01 1.9053791e-03 7.5959921e-05 1.0571276e-03] [1. 0. 0. 0.]\n",
      "85 [9.8118019e-01 3.2935085e-04 6.7627705e-03 1.1727710e-02] [1. 0. 0. 0.]\n",
      "86 [9.9985111e-01 1.2145062e-04 7.7331043e-07 2.6659245e-05] [1. 0. 0. 0.]\n",
      "87 [9.995152e-01 4.763043e-04 5.211945e-07 8.028338e-06] [1. 0. 0. 0.]\n",
      "88 [9.7559786e-01 1.7257826e-02 6.9388309e-03 2.0546923e-04] [1. 0. 0. 0.]\n",
      "89 [9.9998271e-01 1.4123717e-07 3.0571289e-06 1.4045797e-05] [1. 0. 0. 0.]\n",
      "90 [9.9869090e-01 1.3580646e-05 2.4681442e-04 1.0487052e-03] [1. 0. 0. 0.]\n",
      "91 [9.9977130e-01 1.0869679e-06 5.4959753e-07 2.2708609e-04] [1. 0. 0. 0.]\n",
      "92 [9.9935383e-01 1.2662505e-06 1.5025170e-06 6.4340903e-04] [1. 0. 0. 0.]\n",
      "93 [9.9939227e-01 2.5127159e-04 3.6284769e-06 3.5284879e-04] [1. 0. 0. 0.]\n",
      "94 [0.8839373  0.11393335 0.00121638 0.00091293] [1. 0. 0. 0.]\n",
      "95 [9.9834692e-01 8.5642166e-04 1.4062549e-04 6.5601215e-04] [1. 0. 0. 0.]\n",
      "96 [9.9517930e-01 7.0703165e-05 1.6377495e-04 4.5862687e-03] [1. 0. 0. 0.]\n",
      "97 [3.9475872e-03 9.9424791e-01 1.4404772e-03 3.6401383e-04] [0. 1. 0. 0.]\n",
      "98 [4.2778373e-04 9.9945074e-01 1.1557620e-04 5.8127748e-06] [0. 1. 0. 0.]\n",
      "99 [1.5086869e-03 9.9741286e-01 9.4208989e-04 1.3633484e-04] [0. 1. 0. 0.]\n",
      "100 [2.3606101e-04 9.9948812e-01 2.7159782e-04 4.1684548e-06] [0. 1. 0. 0.]\n",
      "101 [6.5224210e-04 9.9928564e-01 6.1054227e-05 1.0596241e-06] [0. 1. 0. 0.]\n",
      "102 [9.4507297e-05 9.9819523e-01 1.0400753e-03 6.7020248e-04] [0. 1. 0. 0.]\n",
      "103 [9.4361334e-05 9.9820971e-01 1.0315358e-03 6.6437665e-04] [0. 1. 0. 0.]\n",
      "104 [9.4534415e-05 9.9819785e-01 1.0381485e-03 6.6950603e-04] [0. 1. 0. 0.]\n",
      "105 [1.0176246e-04 9.9814200e-01 1.0645572e-03 6.9173402e-04] [0. 1. 0. 0.]\n",
      "106 [1.0189963e-04 9.9814343e-01 1.0644211e-03 6.9019763e-04] [0. 1. 0. 0.]\n",
      "107 [9.4361334e-05 9.9820971e-01 1.0315358e-03 6.6437665e-04] [0. 1. 0. 0.]\n",
      "108 [9.4534415e-05 9.9819785e-01 1.0381485e-03 6.6950603e-04] [0. 1. 0. 0.]\n",
      "109 [4.7323193e-02 9.5048070e-01 8.9310680e-04 1.3030727e-03] [0. 1. 0. 0.]\n",
      "110 [0.02586049 0.9253592  0.00911024 0.03967004] [0. 1. 0. 0.]\n",
      "111 [0.00189768 0.9930201  0.00153798 0.00354427] [0. 1. 0. 0.]\n",
      "112 [0.00484329 0.99142754 0.00150593 0.00222328] [0. 1. 0. 0.]\n",
      "113 [0.00152783 0.9912271  0.00540723 0.00183796] [0. 1. 0. 0.]\n",
      "114 [2.8538022e-02 9.6985561e-01 7.3910783e-08 1.6062446e-03] [0. 1. 0. 0.]\n",
      "115 [1.7021016e-04 9.9903786e-01 3.1843173e-04 4.7350631e-04] [0. 1. 0. 0.]\n",
      "116 [1.8064142e-04 9.9908781e-01 3.9699901e-04 3.3458404e-04] [0. 1. 0. 0.]\n",
      "117 [3.5799012e-04 9.9664491e-01 1.5435792e-03 1.4535199e-03] [0. 1. 0. 0.]\n",
      "118 [6.1040540e-04 9.9501282e-01 3.0045838e-03 1.3720912e-03] [0. 1. 0. 0.]\n",
      "119 [2.1486594e-04 9.9858981e-01 5.6761404e-04 6.2771322e-04] [0. 1. 0. 0.]\n",
      "120 [8.4008199e-05 9.9955922e-01 2.0681582e-04 1.4987739e-04] [0. 1. 0. 0.]\n",
      "121 [0.00819794 0.96368754 0.02537369 0.00274077] [0. 1. 0. 0.]\n",
      "122 [9.99367610e-03 9.81942952e-01 8.05142801e-03 1.19171245e-05] [0. 1. 0. 0.]\n",
      "123 [2.6622640e-06 9.9953246e-01 4.6007350e-04 4.7128392e-06] [0. 1. 0. 0.]\n",
      "124 [2.2393644e-04 9.9939442e-01 3.8128055e-04 3.7102885e-07] [0. 1. 0. 0.]\n",
      "125 [2.0402802e-06 9.9438274e-01 5.6055542e-03 9.6169479e-06] [0. 1. 0. 0.]\n",
      "126 [4.8908852e-03 9.9428070e-01 8.2310493e-04 5.3347776e-06] [0. 1. 0. 0.]\n",
      "127 [4.4882447e-03 9.9302095e-01 2.4703208e-03 2.0500176e-05] [0. 1. 0. 0.]\n",
      "128 [7.2122196e-04 9.9342394e-01 5.5408599e-03 3.1395000e-04] [0. 1. 0. 0.]\n",
      "129 [1.0241285e-03 9.9854702e-01 4.0943309e-04 1.9436593e-05] [0. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 [3.6766909e-05 9.9995840e-01 4.8301517e-06 4.0236028e-08] [0. 1. 0. 0.]\n",
      "131 [2.3853947e-05 9.9962008e-01 3.3454396e-04 2.1426693e-05] [0. 1. 0. 0.]\n",
      "132 [5.9541816e-07 9.9945623e-01 4.6620442e-04 7.7016921e-05] [0. 1. 0. 0.]\n",
      "133 [6.4940838e-04 9.9885023e-01 4.9671117e-04 3.7470293e-06] [0. 1. 0. 0.]\n",
      "134 [2.7296727e-04 9.9971777e-01 3.9959633e-07 8.7635635e-06] [0. 1. 0. 0.]\n",
      "135 [9.7028016e-05 9.9987042e-01 3.1695894e-05 8.8683839e-07] [0. 1. 0. 0.]\n",
      "136 [1.0495421e-03 9.9859136e-01 3.4808402e-04 1.0892408e-05] [0. 1. 0. 0.]\n",
      "137 [1.1947497e-03 9.9833894e-01 4.5025145e-04 1.6105243e-05] [0. 1. 0. 0.]\n",
      "138 [1.2342958e-03 9.9584585e-01 2.8808897e-03 3.8969178e-05] [0. 1. 0. 0.]\n",
      "139 [8.1225665e-04 9.9886703e-01 3.1801799e-04 2.6864366e-06] [0. 1. 0. 0.]\n",
      "140 [4.483249e-04 9.982925e-01 1.258552e-03 6.055654e-07] [0. 1. 0. 0.]\n",
      "141 [2.6733484e-05 9.9949062e-01 4.8066952e-04 1.9636300e-06] [0. 1. 0. 0.]\n",
      "142 [4.1084713e-05 9.9995434e-01 4.4894014e-06 1.2264044e-07] [0. 1. 0. 0.]\n",
      "143 [5.3522745e-03 9.9464285e-01 2.5234752e-07 4.6197015e-06] [0. 1. 0. 0.]\n",
      "144 [1.4098872e-04 9.9766737e-01 3.1179169e-04 1.8797995e-03] [0. 1. 0. 0.]\n",
      "145 [1.8806566e-07 9.9984968e-01 1.3171973e-04 1.8341783e-05] [0. 1. 0. 0.]\n",
      "146 [2.7131462e-05 9.9783915e-01 1.9079959e-03 2.2582970e-04] [0. 1. 0. 0.]\n",
      "147 [3.4550054e-04 9.9964702e-01 6.1862033e-06 1.3588545e-06] [0. 1. 0. 0.]\n",
      "148 [8.8355104e-03 9.6583205e-01 2.5326574e-02 5.8860583e-06] [0. 1. 0. 0.]\n",
      "149 [3.1009282e-03 9.9669868e-01 1.8739479e-04 1.2902143e-05] [0. 1. 0. 0.]\n",
      "150 [1.7075778e-03 9.9279565e-01 5.4961401e-03 5.7135111e-07] [0. 1. 0. 0.]\n",
      "151 [1.4623262e-03 9.9683529e-01 1.6868818e-03 1.5577236e-05] [0. 1. 0. 0.]\n",
      "152 [1.7110244e-04 9.9980754e-01 2.0652724e-05 6.7759856e-07] [0. 1. 0. 0.]\n",
      "153 [2.7821879e-03 9.9630284e-01 9.1102847e-04 3.9622796e-06] [0. 1. 0. 0.]\n",
      "154 [1.1564212e-04 9.9983191e-01 5.2258125e-05 1.1075749e-07] [0. 1. 0. 0.]\n",
      "155 [1.7260846e-03 9.9811041e-01 1.4694557e-04 1.6539561e-05] [0. 1. 0. 0.]\n",
      "156 [9.7128041e-03 9.8303092e-01 7.2463448e-03 1.0002282e-05] [0. 1. 0. 0.]\n",
      "157 [6.9996880e-05 9.9990427e-01 2.4406590e-05 1.3600005e-06] [0. 1. 0. 0.]\n",
      "158 [4.2354069e-03 9.9446493e-01 1.2749225e-03 2.4797189e-05] [0. 1. 0. 0.]\n",
      "159 [4.6772824e-04 9.9946553e-01 6.1160747e-05 5.5463483e-06] [0. 1. 0. 0.]\n",
      "160 [1.0466213e-06 9.9892175e-01 1.0351259e-03 4.2142230e-05] [0. 1. 0. 0.]\n",
      "161 [6.8053401e-07 9.9951756e-01 4.7456977e-04 7.1512072e-06] [0. 1. 0. 0.]\n",
      "162 [7.5079652e-04 9.9819738e-01 1.0315535e-03 2.0326406e-05] [0. 1. 0. 0.]\n",
      "163 [3.8396590e-03 9.9598169e-01 1.2242503e-04 5.6283050e-05] [0. 1. 0. 0.]\n",
      "164 [1.4673471e-03 9.9769139e-01 8.2910131e-04 1.2089605e-05] [0. 1. 0. 0.]\n",
      "165 [3.521071e-04 9.995053e-01 9.377222e-05 4.887374e-05] [0. 1. 0. 0.]\n",
      "166 [7.0847239e-04 9.9928695e-01 1.2276349e-06 3.3845822e-06] [0. 1. 0. 0.]\n",
      "167 [1.6141922e-03 9.9837828e-01 1.7578922e-06 5.7404000e-06] [0. 1. 0. 0.]\n",
      "168 [4.2754796e-06 9.9582916e-01 4.1597695e-03 6.8143222e-06] [0. 1. 0. 0.]\n",
      "169 [1.9482795e-05 9.9545562e-01 4.5084986e-03 1.6421734e-05] [0. 1. 0. 0.]\n",
      "170 [2.6040041e-04 9.9875832e-01 9.7325462e-04 7.9271185e-06] [0. 1. 0. 0.]\n",
      "171 [6.5825932e-04 9.9425346e-01 4.8209000e-03 2.6742631e-04] [0. 1. 0. 0.]\n",
      "172 [1.5657303e-04 9.9980706e-01 1.1445021e-05 2.4922600e-05] [0. 1. 0. 0.]\n",
      "173 [5.9783286e-03 9.9173534e-01 2.2644331e-03 2.1904865e-05] [0. 1. 0. 0.]\n",
      "174 [1.9713047e-04 9.9969590e-01 3.6811103e-05 7.0170281e-05] [0. 1. 0. 0.]\n",
      "175 [1.1752787e-03 9.9849868e-01 2.1674253e-04 1.0929839e-04] [0. 1. 0. 0.]\n",
      "176 [2.1237528e-04 9.9976689e-01 2.9302169e-06 1.7757289e-05] [0. 1. 0. 0.]\n",
      "177 [4.6395091e-04 9.9945074e-01 1.0791452e-05 7.4409625e-05] [0. 1. 0. 0.]\n",
      "178 [4.1432148e-05 3.9734939e-05 9.9682367e-01 3.0951565e-03] [0. 0. 1. 0.]\n",
      "179 [1.2825335e-05 6.9832327e-05 9.9889779e-01 1.0195482e-03] [0. 0. 1. 0.]\n",
      "180 [1.0286638e-05 9.7068827e-05 9.9980563e-01 8.7119297e-05] [0. 0. 1. 0.]\n",
      "181 [1.3764676e-05 9.9689735e-04 9.9898309e-01 6.2087711e-06] [0. 0. 1. 0.]\n",
      "182 [4.9893733e-04 5.3680735e-04 9.9895930e-01 4.9318896e-06] [0. 0. 1. 0.]\n",
      "183 [0.00570397 0.00648432 0.9368034  0.05100834] [0. 0. 1. 0.]\n",
      "184 [3.4407938e-05 4.1374923e-03 9.9467492e-01 1.1531791e-03] [0. 0. 1. 0.]\n",
      "185 [2.80360211e-07 1.07476546e-04 9.99887466e-01 4.75805064e-06] [0. 0. 1. 0.]\n",
      "186 [9.6792320e-04 4.0939840e-04 9.7986263e-01 1.8760135e-02] [0. 0. 1. 0.]\n",
      "187 [5.5206153e-03 5.7292619e-04 9.5220858e-01 4.1697800e-02] [0. 0. 1. 0.]\n",
      "188 [0.00129964 0.00468883 0.98933804 0.00467348] [0. 0. 1. 0.]\n",
      "189 [0.00189274 0.00472012 0.98454213 0.00884497] [0. 0. 1. 0.]\n",
      "190 [1.81302621e-05 7.02974212e-04 9.99156952e-01 1.21964316e-04] [0. 0. 1. 0.]\n",
      "191 [9.9154992e-04 6.0577619e-05 9.7782296e-01 2.1124983e-02] [0. 0. 1. 0.]\n",
      "192 [1.3718531e-04 1.6359125e-05 9.9688596e-01 2.9604814e-03] [0. 0. 1. 0.]\n",
      "193 [1.0561937e-04 2.7185821e-03 9.9215311e-01 5.0226361e-03] [0. 0. 1. 0.]\n",
      "194 [0.001377   0.03410487 0.96336615 0.00115208] [0. 0. 1. 0.]\n",
      "195 [5.7407439e-04 8.6241746e-03 9.9059147e-01 2.1035496e-04] [0. 0. 1. 0.]\n",
      "196 [1.0090728e-03 3.4218126e-03 9.9528211e-01 2.8694575e-04] [0. 0. 1. 0.]\n",
      "197 [0.00189276 0.00488472 0.9812882  0.0119344 ] [0. 0. 1. 0.]\n",
      "198 [0.00432898 0.0021605  0.9795125  0.01399791] [0. 0. 1. 0.]\n",
      "199 [6.3879427e-04 5.7812133e-03 9.9186534e-01 1.7145996e-03] [0. 0. 1. 0.]\n",
      "200 [0.00279875 0.00282552 0.9793117  0.0150639 ] [0. 0. 1. 0.]\n",
      "201 [0.02467611 0.01114265 0.9217302  0.042451  ] [0. 0. 1. 0.]\n",
      "202 [2.6538607e-04 1.6483910e-02 9.8320490e-01 4.5808116e-05] [0. 0. 1. 0.]\n",
      "203 [0.00135413 0.00725647 0.9898582  0.00153116] [0. 0. 1. 0.]\n",
      "204 [6.8525877e-04 3.7125573e-03 9.9149781e-01 4.1042934e-03] [0. 0. 1. 0.]\n",
      "205 [0.00367421 0.01023872 0.98106647 0.00502057] [0. 0. 1. 0.]\n",
      "206 [4.6525314e-04 7.3586856e-03 9.9109006e-01 1.0860487e-03] [0. 0. 1. 0.]\n",
      "207 [0.00188962 0.0056249  0.9824148  0.01007065] [0. 0. 1. 0.]\n",
      "208 [1.05748495e-05 9.96033923e-05 9.99889493e-01 3.39546318e-07] [0. 0. 1. 0.]\n",
      "209 [4.2918405e-06 5.2793662e-04 9.9920899e-01 2.5877939e-04] [0. 0. 1. 0.]\n",
      "210 [6.3163252e-06 6.6068383e-06 9.9822682e-01 1.7602533e-03] [0. 0. 1. 0.]\n",
      "211 [3.9833281e-05 5.1849689e-05 9.9990666e-01 1.7045502e-06] [0. 0. 1. 0.]\n",
      "212 [3.3379172e-05 2.7323856e-06 9.9957436e-01 3.8955786e-04] [0. 0. 1. 0.]\n",
      "213 [1.2836065e-03 3.1988991e-05 9.9867803e-01 6.3540060e-06] [0. 0. 1. 0.]\n",
      "214 [1.4593554e-05 4.8757510e-04 9.9949658e-01 1.2535202e-06] [0. 0. 1. 0.]\n",
      "215 [5.294063e-04 6.016475e-04 9.988637e-01 5.222811e-06] [0. 0. 1. 0.]\n",
      "216 [1.0324615e-05 1.2678177e-03 9.9872118e-01 6.7210306e-07] [0. 0. 1. 0.]\n",
      "217 [1.6710371e-07 1.9887993e-03 9.9797946e-01 3.1646756e-05] [0. 0. 1. 0.]\n",
      "218 [4.1381286e-06 1.1746730e-03 9.9881870e-01 2.4313513e-06] [0. 0. 1. 0.]\n",
      "219 [3.3697564e-02 1.3242984e-04 9.6613985e-01 3.0124711e-05] [0. 0. 1. 0.]\n",
      "220 [1.2721601e-03 1.9727601e-04 9.9851424e-01 1.6285938e-05] [0. 0. 1. 0.]\n",
      "221 [4.9749733e-04 5.6289544e-04 9.9893481e-01 4.7819444e-06] [0. 0. 1. 0.]\n",
      "222 [4.9888790e-06 3.4681342e-03 9.9647790e-01 4.8948987e-05] [0. 0. 1. 0.]\n",
      "223 [1.8626864e-05 7.7251294e-05 9.9990249e-01 1.6744814e-06] [0. 0. 1. 0.]\n",
      "224 [3.2485905e-03 1.9657094e-04 9.9649626e-01 5.8605463e-05] [0. 0. 1. 0.]\n",
      "225 [1.7270239e-03 2.4254793e-04 9.9802411e-01 6.3924385e-06] [0. 0. 1. 0.]\n",
      "226 [6.2374209e-05 7.0484481e-03 9.9287498e-01 1.4242167e-05] [0. 0. 1. 0.]\n",
      "227 [5.2823540e-05 7.2940566e-05 9.9731427e-01 2.5599396e-03] [0. 0. 1. 0.]\n",
      "228 [1.4532949e-05 3.8378132e-03 9.9614632e-01 1.4217057e-06] [0. 0. 1. 0.]\n",
      "229 [5.4071297e-05 1.8329629e-04 9.9944669e-01 3.1588739e-04] [0. 0. 1. 0.]\n",
      "230 [1.5339052e-02 1.3773591e-03 9.8320639e-01 7.7180986e-05] [0. 0. 1. 0.]\n",
      "231 [1.9672312e-07 5.3367495e-07 9.9980038e-01 1.9888674e-04] [0. 0. 1. 0.]\n",
      "232 [1.3863570e-05 1.5808522e-05 9.9869990e-01 1.2703984e-03] [0. 0. 1. 0.]\n",
      "233 [2.3239667e-03 2.1069130e-04 9.9746358e-01 1.8234107e-06] [0. 0. 1. 0.]\n",
      "234 [1.2518468e-03 1.4413285e-04 9.9859351e-01 1.0539008e-05] [0. 0. 1. 0.]\n",
      "235 [2.9876648e-04 5.8041397e-03 9.9356467e-01 3.3252404e-04] [0. 0. 1. 0.]\n",
      "236 [4.4181223e-05 6.9059766e-05 9.9667490e-01 3.2118135e-03] [0. 0. 1. 0.]\n",
      "237 [2.6055139e-05 2.0925582e-03 9.9788070e-01 6.6318103e-07] [0. 0. 1. 0.]\n",
      "238 [2.2398614e-05 1.7775588e-04 9.9979883e-01 9.6296617e-07] [0. 0. 1. 0.]\n",
      "239 [6.2666938e-04 7.3686941e-04 9.9863106e-01 5.4228044e-06] [0. 0. 1. 0.]\n",
      "240 [6.7314673e-03 5.7468478e-05 9.9320978e-01 1.2102637e-06] [0. 0. 1. 0.]\n",
      "241 [1.2392822e-03 3.4341827e-04 9.9840873e-01 8.6677210e-06] [0. 0. 1. 0.]\n",
      "242 [8.5456204e-06 1.8620292e-04 9.9980456e-01 6.6729882e-07] [0. 0. 1. 0.]\n",
      "243 [5.1109619e-06 1.2797955e-03 9.9870968e-01 5.4359643e-06] [0. 0. 1. 0.]\n",
      "244 [1.8331421e-05 7.3375530e-04 9.9924755e-01 3.5570528e-07] [0. 0. 1. 0.]\n",
      "245 [1.5834194e-03 2.0729950e-04 9.9820793e-01 1.3151949e-06] [0. 0. 1. 0.]\n",
      "246 [2.6426182e-05 3.8803488e-04 9.9941134e-01 1.7415684e-04] [0. 0. 1. 0.]\n",
      "247 [4.3315929e-05 5.8382312e-03 9.9411726e-01 1.1746921e-06] [0. 0. 1. 0.]\n",
      "248 [1.3871576e-05 1.1405111e-04 9.9987149e-01 5.5519916e-07] [0. 0. 1. 0.]\n",
      "249 [1.5802518e-05 7.8750239e-04 9.9919397e-01 2.6376665e-06] [0. 0. 1. 0.]\n",
      "250 [6.4685605e-03 6.2924798e-04 9.9289602e-01 6.2349513e-06] [0. 0. 1. 0.]\n",
      "251 [3.1709960e-03 1.6624348e-03 9.9515682e-01 9.6844005e-06] [0. 0. 1. 0.]\n",
      "252 [8.4644103e-05 3.5442580e-03 9.9631894e-01 5.2160602e-05] [0. 0. 1. 0.]\n",
      "253 [9.8470668e-04 4.4681990e-04 9.9856108e-01 7.3939264e-06] [0. 0. 1. 0.]\n",
      "254 [1.3355092e-02 1.4175583e-02 9.7244352e-01 2.5834506e-05] [0. 0. 1. 0.]\n",
      "255 [6.8975067e-05 1.2330635e-04 9.9963832e-01 1.6934650e-04] [0. 0. 1. 0.]\n",
      "256 [3.440820e-08 1.263545e-05 9.999808e-01 6.571315e-06] [0. 0. 1. 0.]\n",
      "257 [1.0351931e-04 5.8067078e-05 9.9896991e-01 8.6856337e-04] [0. 0. 1. 0.]\n",
      "258 [3.3489664e-03 8.7578560e-04 9.9576735e-01 7.8737303e-06] [0. 0. 1. 0.]\n",
      "259 [5.3105148e-04 5.9380900e-04 9.9886984e-01 5.3050503e-06] [0. 0. 1. 0.]\n",
      "260 [1.3882911e-03 4.2976400e-05 9.9856359e-01 5.0982981e-06] [0. 0. 1. 0.]\n",
      "261 [4.8180311e-05 3.7094241e-03 9.9624133e-01 1.0312783e-06] [0. 0. 1. 0.]\n",
      "262 [2.6214568e-05 3.0191420e-06 9.9856383e-01 1.4070233e-03] [0. 0. 1. 0.]\n",
      "263 [4.0467319e-04 7.1196537e-04 9.9886537e-01 1.7969640e-05] [0. 0. 1. 0.]\n",
      "264 [1.0373665e-03 1.2578744e-03 9.9770230e-01 2.5012671e-06] [0. 0. 1. 0.]\n",
      "265 [1.5131399e-05 8.9295564e-04 9.9909067e-01 1.2873910e-06] [0. 0. 1. 0.]\n",
      "266 [1.2285960e-03 3.3516606e-04 9.9842823e-01 8.0570326e-06] [0. 0. 1. 0.]\n",
      "267 [1.7577093e-03 2.2683377e-04 9.9799687e-01 1.8555107e-05] [0. 0. 1. 0.]\n",
      "268 [1.4102819e-03 4.6784387e-04 9.9809796e-01 2.3886731e-05] [0. 0. 1. 0.]\n",
      "269 [1.2830169e-07 4.9562198e-07 9.9999416e-01 5.2508340e-06] [0. 0. 1. 0.]\n",
      "270 [2.1075281e-05 1.7802124e-03 9.9819595e-01 2.7565959e-06] [0. 0. 1. 0.]\n",
      "271 [1.0949767e-05 4.9423279e-06 9.9979228e-01 1.9183609e-04] [0. 0. 1. 0.]\n",
      "272 [5.2918054e-08 3.2781763e-04 9.9966347e-01 8.7339859e-06] [0. 0. 1. 0.]\n",
      "273 [4.6103323e-04 5.1065313e-04 9.9902368e-01 4.6765431e-06] [0. 0. 1. 0.]\n",
      "274 [1.2773265e-05 6.7054767e-05 9.9887508e-01 1.0451328e-03] [0. 0. 1. 0.]\n",
      "275 [1.6292584e-05 2.4958723e-03 9.9748719e-01 6.8080919e-07] [0. 0. 1. 0.]\n",
      "276 [2.0727904e-03 3.9693606e-04 9.9751091e-01 1.9394402e-05] [0. 0. 1. 0.]\n",
      "277 [9.3638146e-06 9.5306914e-03 9.9044180e-01 1.8266008e-05] [0. 0. 1. 0.]\n",
      "278 [1.2825335e-05 6.9832327e-05 9.9889779e-01 1.0195482e-03] [0. 0. 1. 0.]\n",
      "279 [3.5526752e-04 2.8347309e-05 9.9527079e-01 4.3456284e-03] [0. 0. 1. 0.]\n",
      "280 [1.6858896e-05 6.8747037e-04 9.9929535e-01 2.8411168e-07] [0. 0. 1. 0.]\n",
      "281 [5.2593718e-04 6.0126092e-04 9.9886763e-01 5.1934130e-06] [0. 0. 1. 0.]\n",
      "282 [6.4505148e-04 5.6254794e-04 9.9879044e-01 1.9488043e-06] [0. 0. 1. 0.]\n",
      "283 [2.7971596e-03 6.8936293e-04 9.9648005e-01 3.3451925e-05] [0. 0. 1. 0.]\n",
      "284 [2.0674374e-03 1.9239062e-05 9.9528307e-01 2.6302987e-03] [0. 0. 1. 0.]\n",
      "285 [1.6626431e-06 4.5126077e-04 9.9954259e-01 4.5596566e-06] [0. 0. 1. 0.]\n",
      "286 [1.1683958e-04 1.9274168e-03 9.9777740e-01 1.7834012e-04] [0. 0. 1. 0.]\n",
      "287 [4.6420799e-04 4.8493594e-03 9.9468094e-01 5.4305424e-06] [0. 0. 1. 0.]\n",
      "288 [1.0901962e-06 2.1421540e-04 9.9978238e-01 2.3407538e-06] [0. 0. 1. 0.]\n",
      "289 [7.7823206e-05 4.7856843e-04 9.9944144e-01 2.2220270e-06] [0. 0. 1. 0.]\n",
      "290 [8.7547760e-06 1.5319935e-04 9.9978548e-01 5.2619911e-05] [0. 0. 1. 0.]\n",
      "291 [2.0620787e-06 6.2196887e-05 9.9992740e-01 8.3698051e-06] [0. 0. 1. 0.]\n",
      "292 [0.12234826 0.00930276 0.0149375  0.85341144] [0. 0. 0. 1.]\n",
      "293 [0.13272642 0.0180831  0.03454295 0.8146475 ] [0. 0. 0. 1.]\n",
      "294 [0.12242995 0.0080437  0.01558564 0.8539406 ] [0. 0. 0. 1.]\n",
      "295 [0.04464937 0.0126013  0.11390229 0.8288471 ] [0. 0. 0. 1.]\n",
      "296 [0.00572246 0.00122164 0.01490833 0.97814757] [0. 0. 0. 1.]\n",
      "297 [0.01492918 0.00137912 0.00459273 0.97909904] [0. 0. 0. 1.]\n",
      "298 [0.00835071 0.00697637 0.00533985 0.9793331 ] [0. 0. 0. 1.]\n",
      "299 [0.00977002 0.00290635 0.00260671 0.9847169 ] [0. 0. 0. 1.]\n",
      "300 [0.01412823 0.00816927 0.02031701 0.9573855 ] [0. 0. 0. 1.]\n",
      "301 [1.9575767e-03 3.0026739e-04 2.6360357e-02 9.7138172e-01] [0. 0. 0. 1.]\n",
      "302 [1.0287424e-03 6.5853324e-04 2.0695678e-03 9.9624312e-01] [0. 0. 0. 1.]\n",
      "303 [0.03999382 0.00373708 0.01164906 0.94461995] [0. 0. 0. 1.]\n",
      "304 [8.4158862e-03 3.6969842e-04 4.2376653e-03 9.8697680e-01] [0. 0. 0. 1.]\n",
      "305 [9.2861960e-03 4.4840295e-04 5.3194528e-03 9.8494589e-01] [0. 0. 0. 1.]\n",
      "306 [1.5546249e-03 1.8000886e-05 6.1911106e-04 9.9780828e-01] [0. 0. 0. 1.]\n",
      "307 [9.1183162e-04 2.0178722e-04 1.2371284e-03 9.9764925e-01] [0. 0. 0. 1.]\n",
      "308 [4.4890819e-03 4.5968022e-04 1.3607878e-03 9.9369037e-01] [0. 0. 0. 1.]\n",
      "309 [0.00529182 0.00105518 0.00346755 0.9901855 ] [0. 0. 0. 1.]\n",
      "310 [1.6310370e-03 5.2565174e-05 1.4037206e-03 9.9691272e-01] [0. 0. 0. 1.]\n",
      "311 [1.9273999e-03 4.6788737e-05 8.8674814e-04 9.9713898e-01] [0. 0. 0. 1.]\n",
      "312 [4.2797313e-03 2.2770180e-05 4.5552789e-04 9.9524200e-01] [0. 0. 0. 1.]\n",
      "313 [4.4144955e-03 1.4920621e-04 8.7709376e-04 9.9455923e-01] [0. 0. 0. 1.]\n",
      "314 [2.5434506e-03 2.1688662e-04 9.6873869e-04 9.9627090e-01] [0. 0. 0. 1.]\n",
      "315 [1.9784335e-03 2.3662935e-04 9.7791164e-04 9.9680710e-01] [0. 0. 0. 1.]\n",
      "316 [6.2367758e-03 8.1155144e-05 2.1275498e-03 9.9155444e-01] [0. 0. 0. 1.]\n",
      "317 [2.7202282e-03 3.0963006e-04 6.9188257e-04 9.9627823e-01] [0. 0. 0. 1.]\n",
      "318 [1.5181868e-03 1.7798277e-04 4.9350434e-04 9.9781042e-01] [0. 0. 0. 1.]\n",
      "319 [1.0379477e-03 2.9855198e-04 5.1941030e-04 9.9814415e-01] [0. 0. 0. 1.]\n",
      "320 [1.0821013e-03 2.8025298e-04 7.0002500e-04 9.9793768e-01] [0. 0. 0. 1.]\n",
      "321 [4.6224170e-03 4.3743968e-04 6.7128059e-03 9.8822731e-01] [0. 0. 0. 1.]\n",
      "322 [1.0304638e-03 2.9532466e-04 5.1646749e-04 9.9815768e-01] [0. 0. 0. 1.]\n",
      "323 [0.05974591 0.01581223 0.00392576 0.9205161 ] [0. 0. 0. 1.]\n",
      "324 [0.0202733  0.02128981 0.06797069 0.89046615] [0. 0. 0. 1.]\n",
      "325 [7.1843350e-03 8.9350139e-04 2.0781772e-03 9.8984396e-01] [0. 0. 0. 1.]\n",
      "326 [0.0372534  0.00117797 0.0171375  0.9444311 ] [0. 0. 0. 1.]\n",
      "327 [0.07990263 0.00951771 0.01936977 0.89120996] [0. 0. 0. 1.]\n",
      "328 [0.16224429 0.02156712 0.04630066 0.7698879 ] [0. 0. 0. 1.]\n",
      "329 [0.10553014 0.0134787  0.02173001 0.8592611 ] [0. 0. 0. 1.]\n",
      "330 [0.9198047  0.00999633 0.06308676 0.00711226] [0. 0. 0. 1.]\n",
      "331 [1.7576159e-03 8.4929317e-02 9.1331047e-01 2.5820439e-06] [0. 0. 0. 1.]\n",
      "332 [0.14048886 0.01451112 0.0270027  0.8179974 ] [0. 0. 0. 1.]\n",
      "333 [0.30251548 0.04001805 0.06815495 0.58931154] [0. 0. 0. 1.]\n",
      "334 [0.1006565  0.01177142 0.01996745 0.86760473] [0. 0. 0. 1.]\n",
      "335 [0.19852354 0.00090941 0.01444361 0.7861234 ] [0. 0. 0. 1.]\n",
      "336 [0.14524385 0.02007749 0.04270349 0.79197514] [0. 0. 0. 1.]\n",
      "337 [0.18231036 0.03300595 0.02437178 0.7603119 ] [0. 0. 0. 1.]\n",
      "338 [0.1173804  0.01069632 0.02593214 0.84599113] [0. 0. 0. 1.]\n",
      "339 [0.10552396 0.0091413  0.01720771 0.868127  ] [0. 0. 0. 1.]\n",
      "340 [0.18902569 0.01884405 0.02929994 0.7628303 ] [0. 0. 0. 1.]\n",
      "341 [0.94401616 0.00978355 0.04280105 0.00339916] [0. 0. 0. 1.]\n",
      "342 [0.5920196  0.01116705 0.3950212  0.00179217] [0. 0. 0. 1.]\n",
      "343 [0.18130857 0.02240485 0.04677953 0.74950695] [0. 0. 0. 1.]\n",
      "344 [0.13765942 0.00955631 0.01620726 0.83657706] [0. 0. 0. 1.]\n",
      "345 [0.14625162 0.00971166 0.02212742 0.82190925] [0. 0. 0. 1.]\n",
      "346 [0.13088408 0.01033649 0.02010138 0.83867806] [0. 0. 0. 1.]\n",
      "347 [0.7684014  0.01415636 0.06647178 0.15097047] [0. 0. 0. 1.]\n",
      "348 [0.04077711 0.00766383 0.01103975 0.9405193 ] [0. 0. 0. 1.]\n",
      "349 [0.71571994 0.00988469 0.27341676 0.0009786 ] [0. 0. 0. 1.]\n",
      "350 [9.8507452e-01 9.1630523e-04 2.2907916e-03 1.1718377e-02] [0. 0. 0. 1.]\n",
      "351 [9.8980731e-01 5.0073257e-04 3.3884607e-03 6.3035674e-03] [0. 0. 0. 1.]\n",
      "352 [1.6572943e-04 1.6757613e-03 9.9815196e-01 6.4790715e-06] [0. 0. 0. 1.]\n",
      "353 [0.96361434 0.00132965 0.00364819 0.03140777] [0. 0. 0. 1.]\n",
      "354 [0.15714416 0.0181703  0.0346548  0.7900307 ] [0. 0. 0. 1.]\n",
      "355 [0.18253927 0.02988567 0.02061266 0.76696235] [0. 0. 0. 1.]\n",
      "356 [0.13788363 0.00771926 0.01446155 0.8399356 ] [0. 0. 0. 1.]\n",
      "357 [0.92939866 0.00942049 0.05632141 0.00485948] [0. 0. 0. 1.]\n",
      "358 [0.09836964 0.00797715 0.01834496 0.8753083 ] [0. 0. 0. 1.]\n",
      "359 [0.22778027 0.0113314  0.0361569  0.7247314 ] [0. 0. 0. 1.]\n",
      "360 [0.12728734 0.00751925 0.01292315 0.85227036] [0. 0. 0. 1.]\n",
      "361 [0.13515659 0.01605493 0.02682844 0.8219601 ] [0. 0. 0. 1.]\n",
      "362 [0.0232572  0.00239211 0.03765274 0.93669784] [0. 0. 0. 1.]\n",
      "363 [0.09649102 0.01098638 0.0183198  0.8742028 ] [0. 0. 0. 1.]\n",
      "364 [0.13109447 0.01110332 0.02240354 0.83539873] [0. 0. 0. 1.]\n",
      "365 [0.11978175 0.00725439 0.01971317 0.8532507 ] [0. 0. 0. 1.]\n",
      "366 [9.7861713e-01 1.0437062e-04 1.3725092e-02 7.5534922e-03] [0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train, verbose=1)\n",
    "for i in range(len(prediction)):\n",
    "    print (i, prediction[i], categorical_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x109512b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfuBBeRGNDHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd29e0d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[183])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save('classifier_sim.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00570397, 0.00648432, 0.9368034 , 0.05100834], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005703971721231937,\n",
       " 0.006484320852905512,\n",
       " 0.93680340051651,\n",
       " 0.05100833997130394]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[183].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
